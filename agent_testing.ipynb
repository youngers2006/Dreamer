{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7c9541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1320e8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU selected\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(\"GPU selected\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"CPU selected for debugging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5706da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module): \n",
    "    def __init__(self, hidden_state_dim, latent_num_rows, latent_num_columns, num_filters_1, num_filters_2, hidden_layer_nodes, device='cpu'):\n",
    "        \"\"\"\n",
    "        Takes obseravtion (image in this class) and maps it to a latent state representation through a CNN.\n",
    "        \"\"\" \n",
    "        super().__init__()\n",
    "        self.latent_size = latent_num_rows * latent_num_columns\n",
    "        self.latent_num_rows = latent_num_rows\n",
    "        self.latent_num_columns = latent_num_columns\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=num_filters_1, kernel_size=3, stride=1, padding=1, device=device),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=num_filters_1, out_channels=num_filters_2, kernel_size=3, stride=1, padding=1, device=device),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.AdaptiveAvgPool2d((2, 2))\n",
    "        ) \n",
    "        flattened_feature_size = num_filters_2 * 2 * 2\n",
    "        total_in_features = flattened_feature_size + hidden_state_dim\n",
    "        self.flatten = nn.Flatten(start_dim=2)\n",
    "        self.latent_mapper = nn.Sequential(\n",
    "            nn.Linear(in_features=total_in_features, out_features=hidden_layer_nodes, device=device),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(in_features=hidden_layer_nodes, out_features=self.latent_size, device=device)\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden, observation):\n",
    "        B, S, C, H, W = observation.shape\n",
    "        observation = observation.view(B * S, C, H, W)\n",
    "        features = self.feature_extractor(observation)\n",
    "        _, out_C, out_H, out_W = features.shape\n",
    "        features = features.view(B, S, out_C, out_H, out_W)\n",
    "        features = self.flatten(features)\n",
    "        input = torch.cat((features, hidden), dim=-1)\n",
    "        logits = self.latent_mapper(input)\n",
    "        return logits\n",
    "    \n",
    "    def encode(self, hidden_state, observation):\n",
    "        B, S, _ = hidden_state.shape\n",
    "        logits = self.forward(hidden_state, observation)\n",
    "        logits_reshaped = logits.view(B, S, self.latent_num_rows, self.latent_num_columns)\n",
    "        dist = torch.distributions.Categorical(logits=logits)\n",
    "        sampled_idx = dist.sample()\n",
    "        latent_state_flat = torch.nn.functional.one_hot(sampled_idx, num_classes=self.latent_size)\n",
    "        latent_state = latent_state_flat.view(B, S, self.latent_num_rows, self.latent_num_columns)\n",
    "        return latent_state, logits_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50fab164",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"CarRacing-v3\"\n",
    "env = gym.make(env_id, continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa5440bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 96, 96)\n",
      "(3, 96, 96)\n",
      "[-0.16066334  0.939331    0.6702185 ]\n",
      "6.967137809187279\n",
      "False\n",
      "torch.Size([2, 2, 3, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "action = env.action_space.sample()\n",
    "print(action.shape)\n",
    "observation, _ = env.reset(seed=42)\n",
    "observation_, reward, term, trun, _ = env.step(action)\n",
    "observation = observation.transpose(2,0,1)\n",
    "observation_ = observation_.transpose(2,0,1)\n",
    "print(observation.shape)\n",
    "print(observation_.shape)\n",
    "print(action)\n",
    "print(reward)\n",
    "print(term)\n",
    "\n",
    "observation = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "observation_ = torch.tensor(observation_, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "observations = torch.cat([observation, observation_], dim=0).unsqueeze(0)\n",
    "observations = torch.cat([observations, observations], dim=0)\n",
    "print(observations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b6dcf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(100, 32, 32, 32, 16, 128, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b6983c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 64])\n",
      "torch.Size([2, 2, 100])\n",
      "tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 32, 32])\n",
      "torch.Size([2, 2, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "hiddens = torch.zeros(2, 2, 100, dtype=torch.float32, device=device)\n",
    "latent, logits = encoder.encode(hiddens, observations)\n",
    "print(latent)\n",
    "print(latent.shape) \n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "284bdcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes a latent state and maps it to the image it was created by.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_num_rows, latent_num_columns, observation_dim, hidden_state_dim, num_filters_1, num_filters_2, hidden_layer_nodes, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.upscale_starting_dim = observation_dim[0] // 4\n",
    "        self.num_filters_2 = num_filters_2\n",
    "\n",
    "        self.hidden_dim = hidden_state_dim\n",
    "        self.latent_row_dim = latent_num_rows\n",
    "        self.latent_col_dim = latent_num_columns\n",
    "\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.upscaler = nn.Sequential(\n",
    "            nn.Linear(in_features=latent_num_rows * latent_num_columns + hidden_state_dim, out_features=hidden_layer_nodes, device=device),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(in_features=hidden_layer_nodes, out_features=num_filters_2 * self.upscale_starting_dim * self.upscale_starting_dim, device=device),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        self.image_builder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=num_filters_2, out_channels=num_filters_1, kernel_size=4, stride=2, padding=1, device=device),\n",
    "            nn.SiLU(),\n",
    "            nn.ConvTranspose2d(in_channels=num_filters_1, out_channels=6, kernel_size=4, stride=2, padding=1, device=device)\n",
    "        )\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, hidden: torch.tensor, latent: torch.tensor):\n",
    "        B, S, _ = hidden.shape\n",
    "        hidden = hidden.view(B * S, self.hidden_dim)\n",
    "        latent = latent.view(B * S, self.latent_row_dim, self.latent_col_dim)\n",
    "\n",
    "        latent = self.flatten(latent)\n",
    "        input = torch.cat((hidden, latent), dim=-1)\n",
    "\n",
    "        x = self.upscaler(input)\n",
    "        x = x.view(-1, self.num_filters_2, self.upscale_starting_dim, self.upscale_starting_dim)\n",
    "\n",
    "        obs_params = self.image_builder(x)\n",
    "        mu, sigma_logits = torch.chunk(obs_params, chunks=2, dim=1)\n",
    "        sigma = self.softplus(sigma_logits) + 1e-4\n",
    "\n",
    "        _, C, H, W = mu.shape\n",
    "        mu = mu.view(B, S, C, H, W)\n",
    "        sigma = sigma.view(B, S, C, H, W)\n",
    "        return mu, sigma\n",
    "    \n",
    "    def decode(self, hidden_state: torch.tensor, latent_state: torch.tensor):\n",
    "        mu, sigma = self.forward(hidden_state, latent_state)\n",
    "        dist = torch.distributions.Independent(torch.distributions.Normal(loc=mu, scale=sigma), 3)\n",
    "        observation = dist.rsample()\n",
    "        return observation, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdc9046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(32, 32, (96, 96), 100, 32, 16, 128, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dff8265",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens = torch.zeros(2, 2, 100, dtype=torch.float32, device=device)\n",
    "observation_decode, mu, sigma = decoder.decode(hiddens, latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf8289f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3, 96, 96])\n",
      "torch.Size([2, 2, 3, 96, 96])\n",
      "torch.Size([2, 2, 3, 96, 96])\n",
      "tensor([[[[[ 6.7391e-01, -4.7964e-02, -5.7319e-01,  ..., -4.0895e-01,\n",
      "            -5.4148e-01, -3.7130e-01],\n",
      "           [-1.4428e+00, -4.7047e-01, -5.6548e-01,  ...,  5.4288e-01,\n",
      "             1.3301e+00,  1.4066e+00],\n",
      "           [ 6.3714e-01, -7.5179e-01, -9.0108e-01,  ..., -7.5696e-01,\n",
      "             6.3301e-01, -5.8308e-02],\n",
      "           ...,\n",
      "           [-1.1645e-01,  1.7642e-01, -5.4705e-01,  ...,  2.0863e-01,\n",
      "             1.2980e-01, -6.3522e-01],\n",
      "           [ 6.8784e-01,  2.6905e-01,  5.9810e-01,  ..., -2.4836e-01,\n",
      "             3.8437e-01, -1.5331e-01],\n",
      "           [ 5.2590e-01,  5.5076e-02,  4.4435e-01,  ..., -1.1557e+00,\n",
      "             5.0378e-02, -6.5019e-01]],\n",
      "\n",
      "          [[-4.2576e-01,  5.0399e-01,  1.7178e-01,  ...,  6.1553e-01,\n",
      "             1.0620e-01, -4.8056e-01],\n",
      "           [ 3.6043e-01,  6.3996e-01, -3.9948e-01,  ...,  9.1081e-01,\n",
      "             8.0584e-03,  1.5238e+00],\n",
      "           [-5.4729e-01,  1.5943e-01, -2.4738e-01,  ..., -1.1574e-01,\n",
      "             3.3473e-01,  2.7745e-01],\n",
      "           ...,\n",
      "           [ 6.3205e-01, -1.1237e-01, -6.5505e-01,  ...,  4.4872e-01,\n",
      "             3.1024e-01, -8.9028e-01],\n",
      "           [-1.1363e+00, -5.4553e-01,  3.9320e-01,  ...,  1.2262e+00,\n",
      "            -3.5121e-02, -7.4067e-01],\n",
      "           [-3.5947e-02, -1.2636e-01, -2.8288e-01,  ...,  8.2347e-02,\n",
      "             1.0401e+00,  7.8342e-02]],\n",
      "\n",
      "          [[ 7.4640e-01,  1.6610e-01, -1.1452e+00,  ...,  2.2580e-01,\n",
      "            -5.1416e-01,  2.3551e-01],\n",
      "           [-5.6229e-01,  6.4726e-03, -9.7050e-01,  ..., -2.6202e-01,\n",
      "            -1.1070e-01,  5.3132e-01],\n",
      "           [ 9.1997e-01, -1.9525e-01,  1.1276e+00,  ..., -8.5377e-01,\n",
      "            -6.1974e-01,  3.6411e-03],\n",
      "           ...,\n",
      "           [ 3.5231e-01, -3.1518e-01,  1.6505e-01,  ..., -5.6687e-01,\n",
      "             3.9115e-01,  2.0054e-01],\n",
      "           [-3.7151e-01,  4.8427e-01,  1.1358e+00,  ...,  1.4005e-01,\n",
      "            -1.8316e-01, -9.8059e-01],\n",
      "           [ 1.4080e+00,  2.5080e+00, -3.9392e-01,  ..., -1.7798e-01,\n",
      "            -1.2153e+00, -3.2900e-01]]],\n",
      "\n",
      "\n",
      "         [[[ 1.4711e+00, -5.6542e-01,  8.1967e-01,  ...,  3.1020e-01,\n",
      "             7.1839e-01,  8.0983e-01],\n",
      "           [-9.6005e-01,  8.9518e-01,  1.1545e+00,  ..., -9.3620e-01,\n",
      "             2.0289e-01, -5.5995e-01],\n",
      "           [ 4.3943e-01, -6.9615e-01,  5.3591e-01,  ...,  1.7915e-01,\n",
      "             7.9821e-01,  2.1585e+00],\n",
      "           ...,\n",
      "           [-3.4797e-01, -3.0365e-01, -3.6067e-01,  ...,  4.9452e-01,\n",
      "            -8.6790e-01,  2.6198e-04],\n",
      "           [ 4.1813e-01,  1.0272e+00,  1.8299e-01,  ..., -1.2573e-01,\n",
      "             8.1386e-01,  5.7175e-01],\n",
      "           [ 1.3332e-01, -5.1279e-01, -3.5957e-01,  ..., -8.0739e-01,\n",
      "             2.1869e-01,  2.5761e-01]],\n",
      "\n",
      "          [[ 3.2363e-01, -2.2826e-01,  6.3449e-01,  ..., -1.9773e-01,\n",
      "             3.1369e-01, -3.1509e-01],\n",
      "           [ 1.9386e-01, -9.8798e-02,  8.6993e-01,  ...,  5.0332e-02,\n",
      "             7.8451e-01,  6.2739e-01],\n",
      "           [ 9.2689e-01,  1.5276e+00, -7.2940e-01,  ..., -8.9118e-01,\n",
      "            -6.6608e-01,  8.8953e-01],\n",
      "           ...,\n",
      "           [-3.0090e-01, -6.1911e-01,  1.1255e+00,  ...,  1.1054e+00,\n",
      "             4.9775e-01,  1.2578e-01],\n",
      "           [-3.8612e-01,  2.1895e-01, -2.3677e-01,  ..., -6.4784e-01,\n",
      "             6.9039e-01,  1.9207e-01],\n",
      "           [ 6.7965e-01, -1.2309e+00,  9.3653e-01,  ...,  1.4238e-01,\n",
      "            -1.3288e-01, -3.5510e-01]],\n",
      "\n",
      "          [[-1.8573e-01, -1.4695e+00, -4.4478e-01,  ...,  7.1161e-01,\n",
      "            -3.0115e-01, -8.9651e-02],\n",
      "           [-2.3781e-01,  9.2829e-02,  9.3397e-01,  ...,  2.2792e-01,\n",
      "             2.9500e-01,  2.2856e-01],\n",
      "           [-2.3836e-01, -1.0871e+00,  1.5883e-01,  ...,  5.7519e-02,\n",
      "            -2.1506e-01, -7.7664e-01],\n",
      "           ...,\n",
      "           [-9.9968e-01,  7.3485e-02, -1.0652e+00,  ...,  7.5390e-01,\n",
      "            -1.2464e-01, -1.0296e+00],\n",
      "           [-4.7213e-02, -3.3936e-01,  8.2748e-01,  ...,  1.0242e-02,\n",
      "             8.4622e-01,  6.0317e-01],\n",
      "           [ 3.1466e-01, -2.5087e-02, -2.3891e-01,  ..., -4.8851e-01,\n",
      "             9.7408e-01, -1.1905e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-8.0131e-01,  4.6121e-01, -1.2178e-01,  ...,  5.6603e-01,\n",
      "             1.0767e+00,  3.7674e-01],\n",
      "           [-1.8380e-01,  1.5806e+00, -1.2619e-01,  ...,  5.5939e-01,\n",
      "             1.3606e+00,  7.3728e-01],\n",
      "           [-2.5403e-01, -1.0937e-01, -5.9400e-01,  ...,  5.9917e-01,\n",
      "            -1.1493e+00, -5.8261e-02],\n",
      "           ...,\n",
      "           [-6.1774e-01,  7.6650e-01, -1.0320e+00,  ..., -3.4770e-01,\n",
      "            -1.1725e+00,  7.4769e-02],\n",
      "           [ 5.3540e-01, -7.7433e-02, -2.9568e-01,  ..., -1.3096e-01,\n",
      "            -1.8314e-01, -3.7966e-01],\n",
      "           [-3.4883e-01,  1.1993e+00,  7.3439e-01,  ...,  4.5369e-01,\n",
      "             9.7989e-02,  1.4584e+00]],\n",
      "\n",
      "          [[ 3.3762e-01,  9.2243e-02,  6.9730e-02,  ...,  5.7824e-01,\n",
      "             6.5130e-01, -1.2420e-01],\n",
      "           [ 1.2347e+00, -1.5564e-01,  1.5145e-01,  ..., -1.4582e+00,\n",
      "            -5.7887e-01,  2.4407e-01],\n",
      "           [ 4.3782e-01, -1.7068e-01,  9.9517e-02,  ..., -7.7016e-01,\n",
      "             3.0981e-01, -3.7329e-01],\n",
      "           ...,\n",
      "           [-6.9838e-01, -1.4183e-01, -8.9300e-01,  ...,  1.8041e+00,\n",
      "             7.8430e-01, -4.8817e-01],\n",
      "           [-7.9431e-02,  4.1515e-01, -4.5461e-01,  ..., -3.7464e-02,\n",
      "             2.1528e-01, -5.3899e-01],\n",
      "           [-1.4615e+00, -1.0937e+00,  1.2667e-01,  ...,  3.2469e-01,\n",
      "            -4.1563e-01, -8.6385e-01]],\n",
      "\n",
      "          [[ 1.3865e+00, -9.9936e-01, -2.2344e-01,  ..., -3.0176e-01,\n",
      "             1.9390e-01,  8.3190e-02],\n",
      "           [-4.9770e-01,  5.2285e-01, -5.8950e-01,  ..., -7.8212e-01,\n",
      "            -5.1402e-01,  1.0446e-01],\n",
      "           [ 5.7326e-01, -1.1025e+00,  8.2176e-01,  ..., -5.4022e-01,\n",
      "            -1.0955e+00,  9.4750e-01],\n",
      "           ...,\n",
      "           [-4.1004e-01,  1.9521e+00, -9.0299e-02,  ...,  3.4119e-01,\n",
      "             8.0924e-02,  4.1829e-01],\n",
      "           [-1.1420e+00,  5.5788e-02,  5.0483e-02,  ..., -4.8015e-01,\n",
      "             2.0105e-01,  9.2430e-01],\n",
      "           [ 8.1321e-01, -6.4661e-01,  3.5413e-01,  ...,  1.4317e+00,\n",
      "             3.3900e-01,  4.1393e-01]]],\n",
      "\n",
      "\n",
      "         [[[ 8.1707e-01, -3.1803e-01, -3.7718e-02,  ..., -1.1248e+00,\n",
      "             1.4463e-01,  5.1868e-01],\n",
      "           [ 1.1461e+00,  1.0908e+00, -6.3131e-01,  ...,  1.3356e+00,\n",
      "             1.5594e-01, -4.3448e-01],\n",
      "           [-4.6353e-01,  8.8114e-01, -6.1621e-02,  ..., -3.1595e-01,\n",
      "            -1.3569e+00, -4.1582e-01],\n",
      "           ...,\n",
      "           [ 2.5106e-01,  2.3233e-01, -1.3602e+00,  ..., -4.7025e-01,\n",
      "             3.4351e-01,  5.4561e-01],\n",
      "           [ 7.5580e-01,  1.7871e-01, -8.8092e-01,  ...,  2.6294e-02,\n",
      "            -5.2906e-01, -8.4346e-03],\n",
      "           [-5.9535e-01,  6.4390e-01, -1.4707e+00,  ..., -6.9612e-01,\n",
      "            -5.0072e-01,  4.4928e-01]],\n",
      "\n",
      "          [[ 1.1429e+00, -4.7601e-01, -2.6878e-02,  ..., -5.7652e-01,\n",
      "             4.7330e-01,  1.2709e-01],\n",
      "           [ 3.9213e-01, -6.7955e-02, -1.5991e+00,  ..., -1.2021e-01,\n",
      "             1.4071e-01,  1.7213e-01],\n",
      "           [-5.0220e-02,  3.6467e-02, -4.6585e-01,  ..., -1.2565e+00,\n",
      "             7.4155e-01,  2.5788e-01],\n",
      "           ...,\n",
      "           [ 1.3501e-01,  1.0042e+00,  7.0757e-01,  ...,  1.7635e+00,\n",
      "            -1.8511e+00, -5.9438e-01],\n",
      "           [-7.1295e-01,  1.7389e-01, -2.0202e-01,  ...,  1.3354e-01,\n",
      "            -8.8814e-02, -3.5410e-01],\n",
      "           [ 1.1529e+00,  3.4707e-01, -6.2583e-01,  ..., -9.2639e-01,\n",
      "             8.7042e-02,  2.5563e-02]],\n",
      "\n",
      "          [[ 3.5468e-01, -8.1207e-01, -1.9167e-01,  ..., -5.9073e-02,\n",
      "            -1.5836e+00,  9.0261e-01],\n",
      "           [-1.0109e+00,  3.3836e-01,  1.7123e-01,  ..., -2.7912e-01,\n",
      "             2.6812e-01, -7.3221e-01],\n",
      "           [-1.3513e+00, -1.4671e-01, -6.5744e-01,  ...,  2.0829e-01,\n",
      "             4.1998e-01,  1.3753e-01],\n",
      "           ...,\n",
      "           [-2.3346e-01,  8.8903e-01, -3.0296e-01,  ...,  1.6068e-01,\n",
      "            -4.2578e-01, -2.4813e-01],\n",
      "           [ 4.1410e-01,  9.5740e-02,  6.4356e-01,  ...,  1.6672e-01,\n",
      "             5.6790e-03,  5.4599e-01],\n",
      "           [ 1.0840e-01,  1.1192e+00, -1.4784e+00,  ..., -3.5786e-01,\n",
      "             9.8136e-01, -2.8869e-02]]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(observation_decode.shape)\n",
    "print(mu.shape)\n",
    "print(sigma.shape)\n",
    "print(observation_decode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_RL_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
