{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e49525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as nn\n",
    "import torch.nn\n",
    "import gymnasium as gym\n",
    "from Dreamer import Dreamer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c70dd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU selected\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(\"GPU selected\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"CPU selected for debugging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476c004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dreamer_agent = Dreamer(\n",
    "    hidden_state_dims=100,\n",
    "    latent_state_dims=(32, 32),\n",
    "    observation_dims=(96, 96),\n",
    "    action_dims=3,\n",
    "    world_model_lr=2e-4,\n",
    "    world_model_betas=(0.9,0.999),\n",
    "    world_model_eps=1e-7,\n",
    "    WM_epochs=100,\n",
    "    beta_prediction=0.1,\n",
    "    beta_dynamics=0.5,\n",
    "    beta_representation=1.0,\n",
    "    critic_reward_buckets=255,\n",
    "    encoder_filter_num_1=32,\n",
    "    encoder_filter_num_2=64,\n",
    "    encoder_hidden_layer_nodes=200,\n",
    "    decoder_filter_num_1=64,\n",
    "    decoder_filter_num_2=32,\n",
    "    decoder_hidden_layer_nodes=200,\n",
    "    dyn_pred_hidden_num_nodes_1=200,\n",
    "    dyn_pred_hidden_num_nodes_2=200,\n",
    "    rew_pred_hidden_num_nodes_1=200,\n",
    "    rew_pred_hidden_num_nodes_2=200,\n",
    "    cont_pred_hidden_num_nodes_1=200,\n",
    "    cont_pred_hidden_num_nodes_2=200,\n",
    "    actor_lr=8e-5,\n",
    "    actor_betas=(0.9,0.999),\n",
    "    actor_eps=1e-7,\n",
    "    critic_lr=8e-5,\n",
    "    critic_betas=(0.9,0.999),\n",
    "    critic_eps=1e-7,\n",
    "    AC_epochs=10,\n",
    "    hidden_layer_actor_1_size=400,\n",
    "    hidden_layer_actor_2_size=400,\n",
    "    hidden_layer_critic_1_size=400,\n",
    "    hidden_layer_critic_2_size=400,\n",
    "    horizon=15,\n",
    "    batch_size=30,\n",
    "    training_iterations=40,\n",
    "    random_iterations=40,\n",
    "    nu=0.995,\n",
    "    lambda_=0.95,\n",
    "    gamma=0.99,\n",
    "    buffer_size=150000,\n",
    "    sequence_length=30,\n",
    "    seed=42,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b03204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - WorldModel params: 5452210\n",
      "  - Agent params: 1325461\n",
      "  - Actor params: 612806\n",
      "  - Critic params: 712655\n",
      "  - Encoder params: 296616\n",
      "  - Decoder params: 3968814\n",
      "  - Sequence model params: 338700\n",
      "  - Dynamics predictor params: 266224\n",
      "  - Reward predictor params: 316455\n",
      "  - Continue predictor params: 265401\n"
     ]
    }
   ],
   "source": [
    "print(f\"  - WorldModel params: {sum(p.numel() for p in dreamer_agent.world_model.parameters())}\")\n",
    "print(f\"  - Agent params: {sum(p.numel() for p in dreamer_agent.agent.parameters())}\")\n",
    "print(f\"  - Actor params: {sum(p.numel() for p in dreamer_agent.agent.actor.parameters())}\")\n",
    "print(f\"  - Critic params: {sum(p.numel() for p in dreamer_agent.agent.critic.parameters())}\")\n",
    "print(f\"  - Encoder params: {sum(p.numel() for p in dreamer_agent.world_model.encoder.parameters())}\")\n",
    "print(f\"  - Decoder params: {sum(p.numel() for p in dreamer_agent.world_model.decoder.parameters())}\")\n",
    "print(f\"  - Sequence model params: {sum(p.numel() for p in dreamer_agent.world_model.sequence_model.parameters())}\")\n",
    "print(f\"  - Dynamics predictor params: {sum(p.numel() for p in dreamer_agent.world_model.dynamics_predictor.parameters())}\")\n",
    "print(f\"  - Reward predictor params: {sum(p.numel() for p in dreamer_agent.world_model.reward_predictor.parameters())}\")\n",
    "print(f\"  - Continue predictor params: {sum(p.numel() for p in dreamer_agent.world_model.continue_predictor.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2d6f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"CarRacing-v3\"\n",
    "env = gym.make(env_id, continuous=True)\n",
    "evaluation_env = gym.make(env_id, continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a2616f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "Starting Random Kickstart.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kickstarting Dreamer Agent.:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 14, 1])\n",
      "torch.Size([30, 15, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 14, 1])\n",
      "torch.Size([30, 15, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 14, 1])\n",
      "torch.Size([30, 15, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 14, 1])\n",
      "torch.Size([30, 15, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 14, 1])\n",
      "torch.Size([30, 15, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 14, 1])\n",
      "torch.Size([30, 15, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 14, 1])\n",
      "torch.Size([30, 15, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 14, 1])\n",
      "torch.Size([30, 15, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 14, 1])\n",
      "torch.Size([30, 15, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 14, 1])\n",
      "torch.Size([30, 15, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kickstarting Dreamer Agent.:   2%|â–Ž         | 1/40 [01:50<1:11:53, 110.61s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m torch.autograd.set_detect_anomaly(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m WM_loss_list, actor_loss_list, critic_loss_list, evaluation_list = \u001b[43mdreamer_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_dreamer\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_env\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/Dreamer/Dreamer.py:284\u001b[39m, in \u001b[36mDreamer.train_dreamer\u001b[39m\u001b[34m(self, env, eval_env)\u001b[39m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.random_iterations), desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKickstarting Dreamer Agent.\u001b[39m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    283\u001b[39m     \u001b[38;5;28mself\u001b[39m.rollout_policy(env, random_policy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     WM_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_world_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m     actor_loss, critic_loss = \u001b[38;5;28mself\u001b[39m.train_Agent()\n\u001b[32m    286\u001b[39m     WM_loss_list.append(WM_loss) ; actor_loss_list.append(actor_loss) ; critic_loss_list.append(critic_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/Dreamer/Dreamer.py:202\u001b[39m, in \u001b[36mDreamer.train_world_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.WM_epochs), desc=\u001b[33m\"\u001b[39m\u001b[33mTraining World Model On Buffer Data\u001b[39m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    198\u001b[39m     observation_seq_batch, action_seq_batch, reward_seq_batch, continue_seq_batch, _ = \u001b[38;5;28mself\u001b[39m.buffer.sample_sequences(\n\u001b[32m    199\u001b[39m         batch_size=\u001b[38;5;28mself\u001b[39m.batch_size\n\u001b[32m    200\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     loss_world_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mworld_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation_seq_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_seq_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward_seq_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontinue_seq_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m     loss_list.append(loss_world_model)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss_list\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/Dreamer/WorldModel.py:163\u001b[39m, in \u001b[36mWorldModel.training_step\u001b[39m\u001b[34m(self, observation_sequences, action_sequences, reward_sequences, continue_sequences)\u001b[39m\n\u001b[32m    161\u001b[39m prior_dist = torch.distributions.Categorical(logits=prior_logits)\n\u001b[32m    162\u001b[39m posterior_dist = torch.distributions.Categorical(logits=posterior_logits)\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m Dkl_dyn = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdistributions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkl_divergence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposterior_dist_detached\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior_dist\u001b[49m\u001b[43m)\u001b[49m.sum(dim=-\u001b[32m1\u001b[39m).mean()\n\u001b[32m    164\u001b[39m Dkl_rep = torch.distributions.kl.kl_divergence(posterior_dist, prior_dist_detached).sum(dim=-\u001b[32m1\u001b[39m).mean()\n\u001b[32m    165\u001b[39m loss_pred_batch = - obs_log_lh.sum(dim=[-\u001b[32m3\u001b[39m, -\u001b[32m2\u001b[39m, -\u001b[32m1\u001b[39m]) - rew_log_lh.squeeze(-\u001b[32m1\u001b[39m) - cont_log_lh.squeeze(-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_RL_gym/lib/python3.13/site-packages/torch/distributions/kl.py:192\u001b[39m, in \u001b[36mkl_divergence\u001b[39m\u001b[34m(p, q)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fun \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    190\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo KL(p || q) is implemented for p type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and q type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    191\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_RL_gym/lib/python3.13/site-packages/torch/distributions/kl.py:249\u001b[39m, in \u001b[36m_kl_categorical_categorical\u001b[39m\u001b[34m(p, q)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;129m@register_kl\u001b[39m(Categorical, Categorical)\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_kl_categorical_categorical\u001b[39m(p, q):\n\u001b[32m    248\u001b[39m     t = p.probs * (p.logits - q.logits)\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     t[(\u001b[43mq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprobs\u001b[49m == \u001b[32m0\u001b[39m).expand_as(t)] = inf\n\u001b[32m    250\u001b[39m     t[(p.probs == \u001b[32m0\u001b[39m).expand_as(t)] = \u001b[32m0\u001b[39m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m t.sum(-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_RL_gym/lib/python3.13/site-packages/torch/distributions/utils.py:170\u001b[39m, in \u001b[36mlazy_property.__get__\u001b[39m\u001b[34m(self, instance, obj_type)\u001b[39m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _lazy_property_and_property(\u001b[38;5;28mself\u001b[39m.wrapped)\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[38;5;28msetattr\u001b[39m(instance, \u001b[38;5;28mself\u001b[39m.wrapped.\u001b[34m__name__\u001b[39m, value)\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_RL_gym/lib/python3.13/site-packages/torch/distributions/categorical.py:111\u001b[39m, in \u001b[36mCategorical.probs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;129m@lazy_property\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprobs\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlogits_to_probs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_RL_gym/lib/python3.13/site-packages/torch/distributions/utils.py:98\u001b[39m, in \u001b[36mlogits_to_probs\u001b[39m\u001b[34m(logits, is_binary)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_binary:\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.sigmoid(logits)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_RL_gym/lib/python3.13/site-packages/torch/nn/functional.py:2137\u001b[39m, in \u001b[36msoftmax\u001b[39m\u001b[34m(input, dim, _stacklevel, dtype)\u001b[39m\n\u001b[32m   2135\u001b[39m     dim = _get_softmax_dim(\u001b[33m\"\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m.dim(), _stacklevel)\n\u001b[32m   2136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2137\u001b[39m     ret = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2138\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2139\u001b[39m     ret = \u001b[38;5;28minput\u001b[39m.softmax(dim, dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_RL_gym/lib/python3.13/site-packages/torch/fx/traceback.py:189\u001b[39m, in \u001b[36mformat_stack\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta.get(\u001b[33m\"\u001b[39m\u001b[33mstack_trace\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    188\u001b[39m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtraceback\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_RL_gym/lib/python3.13/traceback.py:45\u001b[39m, in \u001b[36mformat_list\u001b[39m\u001b[34m(extracted_list)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat_list\u001b[39m(extracted_list):\n\u001b[32m     34\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Format a list of tuples or FrameSummary objects for printing.\u001b[39;00m\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m \u001b[33;03m    Given a list of tuples or FrameSummary objects as returned by\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     43\u001b[39m \u001b[33;03m    whose source text line is not None.\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mStackSummary\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_RL_gym/lib/python3.13/traceback.py:757\u001b[39m, in \u001b[36mStackSummary.format\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m count = \u001b[32m0\u001b[39m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m frame_summary \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     formatted_frame = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_frame_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolorize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolorize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m formatted_frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    759\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_RL_gym/lib/python3.13/traceback.py:549\u001b[39m, in \u001b[36mStackSummary.format_frame_summary\u001b[39m\u001b[34m(self, frame_summary, **kwargs)\u001b[39m\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    547\u001b[39m     row.append(\u001b[33m'\u001b[39m\u001b[33m  File \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m, line \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, in \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m    548\u001b[39m         filename, frame_summary.lineno, frame_summary.name))\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mframe_summary\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_dedented_lines\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m frame_summary._dedented_lines.strip():\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    551\u001b[39m         frame_summary.colno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m    552\u001b[39m         frame_summary.end_colno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    553\u001b[39m     ):\n\u001b[32m    554\u001b[39m         \u001b[38;5;66;03m# only output first line if column information is missing\u001b[39;00m\n\u001b[32m    555\u001b[39m         row.append(textwrap.indent(frame_summary.line, \u001b[33m'\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_RL_gym/lib/python3.13/traceback.py:368\u001b[39m, in \u001b[36mFrameSummary._dedented_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28mself\u001b[39m._set_lines()\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lines_dedented \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lines \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[38;5;28mself\u001b[39m._lines_dedented = \u001b[43mtextwrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdedent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lines_dedented\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_RL_gym/lib/python3.13/textwrap.py:435\u001b[39m, in \u001b[36mdedent\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m    432\u001b[39m \u001b[38;5;66;03m# Look for the longest leading string of spaces and tabs common to\u001b[39;00m\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# all lines.\u001b[39;00m\n\u001b[32m    434\u001b[39m margin = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m text = \u001b[43m_whitespace_only_re\u001b[49m\u001b[43m.\u001b[49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    436\u001b[39m indents = _leading_whitespace_re.findall(text)\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m indent \u001b[38;5;129;01min\u001b[39;00m indents:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "WM_loss_list, actor_loss_list, critic_loss_list, evaluation_list = dreamer_agent.train_dreamer(env, evaluation_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ddfc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(WM_loss_list)\n",
    "plt.plot(actor_loss_list)\n",
    "plt.plot(critic_loss_list)\n",
    "plt.plot(evaluation_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_RL_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
