{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e49525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as nn\n",
    "import torch.nn\n",
    "import gymnasium as gym\n",
    "from Dreamer import Dreamer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c70dd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU selected\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(\"GPU selected\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"CPU selected for debugging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dreamer_agent = Dreamer(\n",
    "    hidden_state_dims=100,\n",
    "    latent_state_dims=(32, 32),\n",
    "    observation_dims=(96, 96),\n",
    "    action_dims=3,\n",
    "    world_model_lr=2e-4,\n",
    "    world_model_betas=(0.9,0.999),\n",
    "    world_model_eps=1e-7,\n",
    "    WM_epochs=100,\n",
    "    beta_prediction=1.0,\n",
    "    beta_dynamics=0.1,\n",
    "    beta_representation=1.0,\n",
    "    critic_reward_buckets=255,\n",
    "    encoder_filter_num_1=32,\n",
    "    encoder_filter_num_2=64,\n",
    "    encoder_hidden_layer_nodes=400,\n",
    "    decoder_filter_num_1=64,\n",
    "    decoder_filter_num_2=32,\n",
    "    decoder_hidden_layer_nodes=100,\n",
    "    dyn_pred_hidden_num_nodes_1=100,\n",
    "    dyn_pred_hidden_num_nodes_2=100,\n",
    "    rew_pred_hidden_num_nodes_1=100,\n",
    "    rew_pred_hidden_num_nodes_2=100,\n",
    "    cont_pred_hidden_num_nodes_1=100,\n",
    "    cont_pred_hidden_num_nodes_2=100,\n",
    "    actor_lr=8e-5,\n",
    "    actor_betas=(0.9,0.999),\n",
    "    actor_eps=1e-7,\n",
    "    critic_lr=8e-5,\n",
    "    critic_betas=(0.9,0.999),\n",
    "    critic_eps=1e-7,\n",
    "    AC_epochs=10,\n",
    "    hidden_layer_actor_1_size=100,\n",
    "    hidden_layer_actor_2_size=100,\n",
    "    hidden_layer_critic_1_size=100,\n",
    "    hidden_layer_critic_2_size=100,\n",
    "    horizon=15,\n",
    "    batch_size=30,\n",
    "    training_iterations=10,\n",
    "    random_iterations=50,\n",
    "    nu=0.995,\n",
    "    lambda_=0.95,\n",
    "    gamma=0.99,\n",
    "    buffer_size=100000,\n",
    "    sequence_length=30,\n",
    "    seed=42,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b03204",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"  - WorldModel params: {sum(p.numel() for p in dreamer_agent.world_model.parameters())}\")\n",
    "print(f\"  - Agent params: {sum(p.numel() for p in dreamer_agent.agent.parameters())}\")\n",
    "print(f\"  - Actor params: {sum(p.numel() for p in dreamer_agent.agent.actor.parameters())}\")\n",
    "print(f\"  - Critic params: {sum(p.numel() for p in dreamer_agent.agent.critic.parameters())}\")\n",
    "print(f\"  - Encoder params: {sum(p.numel() for p in dreamer_agent.world_model.encoder.parameters())}\")\n",
    "print(f\"  - Decoder params: {sum(p.numel() for p in dreamer_agent.world_model.decoder.parameters())}\")\n",
    "print(f\"  - Sequence model params: {sum(p.numel() for p in dreamer_agent.world_model.sequence_model.parameters())}\")\n",
    "print(f\"  - Dynamics predictor params: {sum(p.numel() for p in dreamer_agent.world_model.dynamics_predictor.parameters())}\")\n",
    "print(f\"  - Reward predictor params: {sum(p.numel() for p in dreamer_agent.world_model.reward_predictor.parameters())}\")\n",
    "print(f\"  - Continue predictor params: {sum(p.numel() for p in dreamer_agent.world_model.continue_predictor.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d6f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"CarRacing-v3\"\n",
    "env = gym.make(env_id, continuous=True)\n",
    "evaluation_env = gym.make(env_id, continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2616f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "WM_loss_list, actor_loss_list, critic_loss_list, evaluation_list = dreamer_agent.train_dreamer(env, evaluation_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ddfc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(WM_loss_list)\n",
    "plt.plot(actor_loss_list)\n",
    "plt.plot(critic_loss_list)\n",
    "plt.plot(evaluation_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_RL_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
