{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e49525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gymnasium as gym\n",
    "from Dreamer import Dreamer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c70dd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU selected for debugging\n"
     ]
    }
   ],
   "source": [
    "# Force CPU for debugging to avoid memory issues\n",
    "device = 'cpu'\n",
    "print(\"CPU selected for debugging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54d72651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing component creation to isolate the error...\n",
      "Testing WorldModel creation...\n",
      "✗ WorldModel failed: optimizer got an empty parameter list\n",
      "\n",
      "Testing Agent creation...\n",
      "✗ Agent failed: \"attribute 'buckets' already exists\"\n",
      "\n",
      "Testing Buffer creation...\n",
      "✓ Buffer created successfully\n",
      "\n",
      "Component testing complete!\n",
      "✓ Buffer created successfully\n",
      "\n",
      "Component testing complete!\n"
     ]
    }
   ],
   "source": [
    "# Debug: Test each component separately to find the issue\n",
    "print(\"Testing component creation to isolate the error...\")\n",
    "\n",
    "try:\n",
    "    from WorldModel import WorldModel\n",
    "    print(\"Testing WorldModel creation...\")\n",
    "    wm = WorldModel(\n",
    "        hidden_dims=200,\n",
    "        latent_dims=(32, 32),\n",
    "        observation_dims=(96, 96),\n",
    "        action_dims=3,\n",
    "        training_horizon=15,\n",
    "        batch_size=50,\n",
    "        WM_lr=2e-4,\n",
    "        WM_betas=(0.9,0.999),\n",
    "        WM_eps=1e-7,\n",
    "        beta_pred=1.0,\n",
    "        beta_dyn=0.1,\n",
    "        beta_rep=1.0,\n",
    "        num_encoder_filters_1=32,\n",
    "        num_encoder_filters_2=64,\n",
    "        encoder_hidden_layer_nodes=400,\n",
    "        num_decoder_filters_1=64,\n",
    "        num_decoder_filters_2=32,\n",
    "        decoder_hidden_layer_nodes=400,\n",
    "        dyn_pred_hidden_num_nodes_1=400,\n",
    "        dyn_pred_hidden_num_nodes_2=400,\n",
    "        rew_pred_hidden_num_nodes_1=400,\n",
    "        rew_pred_hidden_num_nodes_2=400,\n",
    "        reward_buckets=255,\n",
    "        cont_pred_hidden_num_nodes_1=400,\n",
    "        cont_pred_hidden_num_nodes_2=400,\n",
    "        device=device\n",
    "    )\n",
    "    print(f\"✓ WorldModel created successfully with {sum(p.numel() for p in wm.parameters())} parameters\")\n",
    "    \n",
    "    # Check individual components\n",
    "    print(f\"  - Encoder params: {sum(p.numel() for p in wm.encoder.parameters())}\")\n",
    "    print(f\"  - Decoder params: {sum(p.numel() for p in wm.decoder.parameters())}\")\n",
    "    print(f\"  - Sequence model params: {sum(p.numel() for p in wm.sequence_model.parameters())}\")\n",
    "    print(f\"  - Dynamics predictor params: {sum(p.numel() for p in wm.dynamics_predictor.parameters())}\")\n",
    "    print(f\"  - Reward predictor params: {sum(p.numel() for p in wm.reward_predictor.parameters())}\")\n",
    "    print(f\"  - Continue predictor params: {sum(p.numel() for p in wm.continue_predictor.parameters())}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ WorldModel failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from Agent import Agent\n",
    "    print(\"\\nTesting Agent creation...\")\n",
    "    agent = Agent(\n",
    "        action_dim=3,\n",
    "        latent_dims=(32, 32),\n",
    "        hidden_state_dim=200,\n",
    "        HL_A1=400,\n",
    "        HL_A2=400,\n",
    "        HL_C1=400,\n",
    "        HL_C2=400,\n",
    "        critic_buckets=255,\n",
    "        A_lr=8e-5,\n",
    "        A_betas=(0.9,0.999),\n",
    "        A_eps=1e-7,\n",
    "        C_lr=8e-5,\n",
    "        C_betas=(0.9,0.999),\n",
    "        C_eps=1e-7,\n",
    "        nu=0.995,\n",
    "        lambda_=0.95,\n",
    "        gamma=0.99,\n",
    "        device=device\n",
    "    )\n",
    "    print(f\"✓ Agent created successfully with {sum(p.numel() for p in agent.parameters())} parameters\")\n",
    "    print(f\"  - Actor params: {sum(p.numel() for p in agent.actor.parameters())}\")\n",
    "    print(f\"  - Critic params: {sum(p.numel() for p in agent.critic.parameters())}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Agent failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from Buffer import Buffer\n",
    "    print(\"\\nTesting Buffer creation...\")\n",
    "    buffer = Buffer(\n",
    "        buffer_size=500000,\n",
    "        sequence_length=50,\n",
    "        action_size=3,  # Fixed: changed from action_dims to action_size\n",
    "        observation_dims=(96, 96),\n",
    "        device=device\n",
    "    )\n",
    "    print(\"✓ Buffer created successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Buffer failed: {e}\")\n",
    "\n",
    "print(\"\\nComponent testing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "476c004a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dreamer_agent = \u001b[43mDreamer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_state_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlatent_state_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobservation_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m96\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43maction_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworld_model_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworld_model_betas\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0.999\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworld_model_eps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mWM_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta_prediction\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta_dynamics\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta_representation\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcritic_reward_buckets\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m255\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_filter_num_1\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_filter_num_2\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_layer_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_filter_num_1\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_filter_num_2\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_hidden_layer_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdyn_pred_hidden_num_nodes_1\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdyn_pred_hidden_num_nodes_2\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrew_pred_hidden_num_nodes_1\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrew_pred_hidden_num_nodes_2\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcont_pred_hidden_num_nodes_1\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcont_pred_hidden_num_nodes_2\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactor_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactor_betas\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0.999\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactor_eps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcritic_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcritic_betas\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0.999\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcritic_eps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mAC_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_layer_actor_1_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_layer_actor_2_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_layer_critic_1_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_layer_critic_2_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.995\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.99\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/Dreamer/Dreamer.py:65\u001b[39m, in \u001b[36mDreamer.__init__\u001b[39m\u001b[34m(self, hidden_state_dims, latent_state_dims, observation_dims, action_dims, world_model_lr, world_model_betas, world_model_eps, WM_epochs, beta_prediction, beta_dynamics, beta_representation, critic_reward_buckets, encoder_filter_num_1, encoder_filter_num_2, encoder_hidden_layer_nodes, decoder_filter_num_1, decoder_filter_num_2, decoder_hidden_layer_nodes, dyn_pred_hidden_num_nodes_1, dyn_pred_hidden_num_nodes_2, rew_pred_hidden_num_nodes_1, rew_pred_hidden_num_nodes_2, cont_pred_hidden_num_nodes_1, cont_pred_hidden_num_nodes_2, actor_lr, actor_betas, actor_eps, critic_lr, critic_betas, critic_eps, AC_epochs, hidden_layer_actor_1_size, hidden_layer_actor_2_size, hidden_layer_critic_1_size, hidden_layer_critic_2_size, horizon, batch_size, training_iterations, random_iterations, nu, lambda_, gamma, buffer_size, sequence_length, seed, device)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28mself\u001b[39m.observation_dims = observation_dims\n\u001b[32m     63\u001b[39m \u001b[38;5;28mself\u001b[39m.latent_state_dims = latent_state_dims\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28mself\u001b[39m.world_model = \u001b[43mWorldModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_state_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlatent_state_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobservation_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43maction_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworld_model_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworld_model_betas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworld_model_eps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta_dynamics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta_representation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_filter_num_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_filter_num_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_layer_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_filter_num_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_filter_num_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_hidden_layer_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdyn_pred_hidden_num_nodes_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdyn_pred_hidden_num_nodes_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrew_pred_hidden_num_nodes_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrew_pred_hidden_num_nodes_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcritic_reward_buckets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcont_pred_hidden_num_nodes_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcont_pred_hidden_num_nodes_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28mself\u001b[39m.agent = Agent(\n\u001b[32m     94\u001b[39m     action_dims,\n\u001b[32m     95\u001b[39m     latent_state_dims,\n\u001b[32m   (...)\u001b[39m\u001b[32m    111\u001b[39m     device=device\n\u001b[32m    112\u001b[39m )\n\u001b[32m    113\u001b[39m \u001b[38;5;28mself\u001b[39m.buffer = Buffer(\n\u001b[32m    114\u001b[39m     buffer_size,\n\u001b[32m    115\u001b[39m     sequence_length,\n\u001b[32m   (...)\u001b[39m\u001b[32m    118\u001b[39m     device=device\n\u001b[32m    119\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/Dreamer/WorldModel.py:49\u001b[39m, in \u001b[36mWorldModel.__init__\u001b[39m\u001b[34m(self, hidden_dims, latent_dims, observation_dims, action_dims, training_horizon, batch_size, WM_lr, WM_betas, WM_eps, beta_pred, beta_dyn, beta_rep, num_encoder_filters_1, num_encoder_filters_2, encoder_hidden_layer_nodes, num_decoder_filters_1, num_decoder_filters_2, decoder_hidden_layer_nodes, dyn_pred_hidden_num_nodes_1, dyn_pred_hidden_num_nodes_2, rew_pred_hidden_num_nodes_1, rew_pred_hidden_num_nodes_2, reward_buckets, cont_pred_hidden_num_nodes_1, cont_pred_hidden_num_nodes_2, device)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mself\u001b[39m.horizon = training_horizon\n\u001b[32m     47\u001b[39m \u001b[38;5;28mself\u001b[39m.buckets = reward_buckets\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28mself\u001b[39m.optimiser = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdamW\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWM_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWM_betas\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWM_betas\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWM_eps\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28mself\u001b[39m.beta_pred = beta_pred\n\u001b[32m     56\u001b[39m \u001b[38;5;28mself\u001b[39m.beta_dyn = beta_dyn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_RL_gym/lib/python3.13/site-packages/torch/optim/adamw.py:37\u001b[39m, in \u001b[36mAdamW.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, maximize, foreach, capturable, differentiable, fused)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     24\u001b[39m     params: ParamsT,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     fused: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     36\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_RL_gym/lib/python3.13/site-packages/torch/optim/adam.py:101\u001b[39m, in \u001b[36mAdam.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[39m\n\u001b[32m     86\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTensor betas[1] must be 1-element\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     88\u001b[39m defaults = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     89\u001b[39m     lr=lr,\n\u001b[32m     90\u001b[39m     betas=betas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m     decoupled_weight_decay=decoupled_weight_decay,\n\u001b[32m    100\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_RL_gym/lib/python3.13/site-packages/torch/optim/optimizer.py:395\u001b[39m, in \u001b[36mOptimizer.__init__\u001b[39m\u001b[34m(self, params, defaults)\u001b[39m\n\u001b[32m    393\u001b[39m param_groups = \u001b[38;5;28mlist\u001b[39m(params)\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33moptimizer got an empty parameter list\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param_groups[\u001b[32m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    397\u001b[39m     param_groups = [{\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: param_groups}]\n",
      "\u001b[31mValueError\u001b[39m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "dreamer_agent = Dreamer(\n",
    "    hidden_state_dims=200,\n",
    "    latent_state_dims=(32, 32),\n",
    "    observation_dims=(96, 96),\n",
    "    action_dims=3,\n",
    "    world_model_lr=2e-4,\n",
    "    world_model_betas=(0.9,0.999),\n",
    "    world_model_eps=1e-7,\n",
    "    WM_epochs=100,\n",
    "    beta_prediction=1.0,\n",
    "    beta_dynamics=0.1,\n",
    "    beta_representation=1.0,\n",
    "    critic_reward_buckets=255,\n",
    "    encoder_filter_num_1=32,\n",
    "    encoder_filter_num_2=64,\n",
    "    encoder_hidden_layer_nodes=400,\n",
    "    decoder_filter_num_1=64,\n",
    "    decoder_filter_num_2=32,\n",
    "    decoder_hidden_layer_nodes=400,\n",
    "    dyn_pred_hidden_num_nodes_1=400,\n",
    "    dyn_pred_hidden_num_nodes_2=400,\n",
    "    rew_pred_hidden_num_nodes_1=400,\n",
    "    rew_pred_hidden_num_nodes_2=400,\n",
    "    cont_pred_hidden_num_nodes_1=400,\n",
    "    cont_pred_hidden_num_nodes_2=400,\n",
    "    actor_lr=8e-5,\n",
    "    actor_betas=(0.9,0.999),\n",
    "    actor_eps=1e-7,\n",
    "    critic_lr=8e-5,\n",
    "    critic_betas=(0.9,0.999),\n",
    "    critic_eps=1e-7,\n",
    "    AC_epochs=100,\n",
    "    hidden_layer_actor_1_size=400,\n",
    "    hidden_layer_actor_2_size=400,\n",
    "    hidden_layer_critic_1_size=400,\n",
    "    hidden_layer_critic_2_size=400,\n",
    "    horizon=15,\n",
    "    batch_size=50,\n",
    "    training_iterations=10,\n",
    "    random_iterations=50,\n",
    "    nu=0.995,\n",
    "    lambda_=0.95,\n",
    "    gamma=0.99,\n",
    "    buffer_size=500000,\n",
    "    sequence_length=50,\n",
    "    seed=42,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2d6f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"CarRacing-v3\"\n",
    "env = gym.make(env_id, continuous=True)\n",
    "evaluation_env = gym.make(env_id, continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2616f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "WM_loss_list, actor_loss_list, critic_loss_list, evaluation_list = dreamer_agent.train_dreamer(env, evaluation_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ddfc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(WM_loss_list)\n",
    "plt.plot(actor_loss_list)\n",
    "plt.plot(critic_loss_list)\n",
    "plt.plot(evaluation_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_RL_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
