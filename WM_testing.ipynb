{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7c9541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1320e8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU selected\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(\"GPU selected\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"CPU selected for debugging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7d5706da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module): \n",
    "    def __init__(self, hidden_state_dim, latent_num_rows, latent_num_columns, num_filters_1, num_filters_2, hidden_layer_nodes, device='cpu'):\n",
    "        \"\"\"\n",
    "        Takes obseravtion (image in this class) and maps it to a latent state representation through a CNN.\n",
    "        \"\"\" \n",
    "        super().__init__()\n",
    "        self.latent_size = latent_num_rows * latent_num_columns\n",
    "        self.latent_num_rows = latent_num_rows\n",
    "        self.latent_num_columns = latent_num_columns\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=num_filters_1, kernel_size=3, stride=1, padding=1, device=device),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=num_filters_1, out_channels=num_filters_2, kernel_size=3, stride=1, padding=1, device=device),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.AdaptiveAvgPool2d((2, 2))\n",
    "        ) \n",
    "        flattened_feature_size = num_filters_2 * 2 * 2\n",
    "        total_in_features = flattened_feature_size + hidden_state_dim\n",
    "        self.flatten = nn.Flatten(start_dim=2)\n",
    "        self.latent_mapper = nn.Sequential(\n",
    "            nn.Linear(in_features=total_in_features, out_features=hidden_layer_nodes, device=device),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(in_features=hidden_layer_nodes, out_features=self.latent_size, device=device)\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden, observation):\n",
    "        B, S, C, H, W = observation.shape\n",
    "        observation = observation.view(B * S, C, H, W)\n",
    "        features = self.feature_extractor(observation)\n",
    "        _, out_C, out_H, out_W = features.shape\n",
    "        features = features.view(B, S, out_C, out_H, out_W)\n",
    "        features = self.flatten(features)\n",
    "        print(features.shape)\n",
    "        print(hidden.shape)\n",
    "        input = torch.cat((features, hidden), dim=-1)\n",
    "        logits = self.latent_mapper(input)\n",
    "        return logits\n",
    "    \n",
    "    def encode(self, hidden_state, observation):\n",
    "        B, S, _ = hidden_state.shape\n",
    "        logits = self.forward(hidden_state, observation)\n",
    "        logits_reshaped = logits.view(B, S, self.latent_num_rows, self.latent_num_columns)\n",
    "        dist = torch.distributions.Categorical(logits=logits)\n",
    "        sampled_idx = dist.sample()\n",
    "        latent_state_flat = torch.nn.functional.one_hot(sampled_idx, num_classes=self.latent_size)\n",
    "        latent_state = latent_state_flat.view(B, S, self.latent_num_rows, self.latent_num_columns)\n",
    "        return latent_state, logits_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50fab164",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"CarRacing-v3\"\n",
    "env = gym.make(env_id, continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa5440bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 96, 96)\n",
      "(3, 96, 96)\n",
      "[0.7508009  0.20699303 0.16375159]\n",
      "6.967137809187279\n",
      "False\n",
      "torch.Size([2, 2, 3, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "action = env.action_space.sample()\n",
    "print(action.shape)\n",
    "observation, _ = env.reset(seed=42)\n",
    "observation_, reward, term, trun, _ = env.step(action)\n",
    "observation = observation.transpose(2,0,1)\n",
    "observation_ = observation_.transpose(2,0,1)\n",
    "print(observation.shape)\n",
    "print(observation_.shape)\n",
    "print(action)\n",
    "print(reward)\n",
    "print(term)\n",
    "\n",
    "observation = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "observation_ = torch.tensor(observation_, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "observations = torch.cat([observation, observation_], dim=0).unsqueeze(0)\n",
    "observations = torch.cat([observations, observations], dim=0)\n",
    "print(observations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b6dcf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(100, 32, 32, 32, 16, 128, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b6983c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 64])\n",
      "torch.Size([2, 2, 100])\n",
      "tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 32, 32])\n",
      "torch.Size([2, 2, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "hiddens = torch.zeros(2, 2, 100, dtype=torch.float32, device=device)\n",
    "latent, logits = encoder.encode(hiddens, observations)\n",
    "print(latent)\n",
    "print(latent.shape) \n",
    "print(logits.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_RL_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
