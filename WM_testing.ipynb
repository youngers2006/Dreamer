{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7c9541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1320e8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU selected\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(\"GPU selected\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"CPU selected for debugging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7d5706da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module): \n",
    "    def __init__(self, hidden_state_dim, latent_num_rows, latent_num_columns, num_filters_1, num_filters_2, hidden_layer_nodes, device='cpu'):\n",
    "        \"\"\"\n",
    "        Takes obseravtion (image in this class) and maps it to a latent state representation through a CNN.\n",
    "        \"\"\" \n",
    "        super().__init__()\n",
    "        self.latent_size = latent_num_rows * latent_num_columns\n",
    "        self.latent_num_rows = latent_num_rows\n",
    "        self.latent_num_columns = latent_num_columns\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=num_filters_1, kernel_size=3, stride=1, padding=1, device=device),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=num_filters_1, out_channels=num_filters_2, kernel_size=3, stride=1, padding=1, device=device),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.AdaptiveAvgPool2d((2, 2))\n",
    "        ) \n",
    "        flattened_feature_size = num_filters_2 * 2 * 2\n",
    "        total_in_features = flattened_feature_size + hidden_state_dim\n",
    "        self.flatten = nn.Flatten(start_dim=2)\n",
    "        self.latent_mapper = nn.Sequential(\n",
    "            nn.Linear(in_features=total_in_features, out_features=hidden_layer_nodes, device=device),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(in_features=hidden_layer_nodes, out_features=self.latent_size, device=device)\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden, observation):\n",
    "        B, S, C, H, W = observation.shape\n",
    "        observation = observation.view(B * S, C, H, W)\n",
    "        features = self.feature_extractor(observation)\n",
    "        _, out_C, out_H, out_W = features.shape\n",
    "        features = features.view(B, S, out_C, out_H, out_W)\n",
    "        features = self.flatten(features)\n",
    "        print(features.shape)\n",
    "        print(hidden.shape)\n",
    "        input = torch.cat((features, hidden), dim=-1)\n",
    "        logits = self.latent_mapper(input)\n",
    "        return logits\n",
    "    \n",
    "    def encode(self, hidden_state, observation):\n",
    "        B, S, _ = hidden_state.shape\n",
    "        logits = self.forward(hidden_state, observation)\n",
    "        logits_reshaped = logits.view(B, S, self.latent_num_rows, self.latent_num_columns)\n",
    "        dist = torch.distributions.Categorical(logits=logits)\n",
    "        sampled_idx = dist.sample()\n",
    "        latent_state_flat = torch.nn.functional.one_hot(sampled_idx, num_classes=self.latent_size)\n",
    "        latent_state = latent_state_flat.view(B, S, self.latent_num_rows, self.latent_num_columns)\n",
    "        return latent_state, logits_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50fab164",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"CarRacing-v3\"\n",
    "env = gym.make(env_id, continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa5440bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 96, 96)\n",
      "(3, 96, 96)\n",
      "[0.7508009  0.20699303 0.16375159]\n",
      "6.967137809187279\n",
      "False\n",
      "torch.Size([2, 2, 3, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "action = env.action_space.sample()\n",
    "print(action.shape)\n",
    "observation, _ = env.reset(seed=42)\n",
    "observation_, reward, term, trun, _ = env.step(action)\n",
    "observation = observation.transpose(2,0,1)\n",
    "observation_ = observation_.transpose(2,0,1)\n",
    "print(observation.shape)\n",
    "print(observation_.shape)\n",
    "print(action)\n",
    "print(reward)\n",
    "print(term)\n",
    "\n",
    "observation = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "observation_ = torch.tensor(observation_, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "observations = torch.cat([observation, observation_], dim=0).unsqueeze(0)\n",
    "observations = torch.cat([observations, observations], dim=0)\n",
    "print(observations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b6dcf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(100, 32, 32, 32, 16, 128, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b6983c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 64])\n",
      "torch.Size([2, 2, 100])\n",
      "tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 32, 32])\n",
      "torch.Size([2, 2, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "hiddens = torch.zeros(2, 2, 100, dtype=torch.float32, device=device)\n",
    "latent, logits = encoder.encode(hiddens, observations)\n",
    "print(latent)\n",
    "print(latent.shape) \n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f747eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll_model(\n",
    "            self,\n",
    "            observation_sequence_batch: torch.tensor, \n",
    "            action_sequence_batch: torch.tensor, \n",
    "            reward_sequence_batch: torch.tensor, \n",
    "            continue_sequence_batch: torch.tensor\n",
    "        ):\n",
    "        def single_sequence_unroll(observation_sequence, action_sequence, reward_sequence, continue_sequence):\n",
    "            posterior_logits = []\n",
    "            prior_logits = []\n",
    "            obs_likelyhood_seq = []\n",
    "            rew_likelyhood_seq = [] \n",
    "            cont_likelyhood_seq = []\n",
    "\n",
    "            observation_sequence = observation_sequence.unsqueeze(0)\n",
    "            action_sequence = action_sequence.unsqueeze(0)\n",
    "            reward_sequence = reward_sequence.unsqueeze(0)\n",
    "            continue_sequence = continue_sequence.unsqueeze(0)\n",
    "\n",
    "            hidden_state = torch.zeros(1, 1, self.hidden_dims, device=self.device)\n",
    "            posterior_latent = torch.zeros(1, 1, self.latent_num_rows, self.latent_num_columns, device=self.device)\n",
    "\n",
    "            for t in range(self.horizon):\n",
    "                prev_action = action_sequence[:, t-1:t] if t > 0 else torch.zeros(1, 1, self.action_dims, device=self.device)\n",
    "                posterior_latent, hidden_state, posterior_logits_t = self.observe_step(\n",
    "                    posterior_latent,\n",
    "                    hidden_state,\n",
    "                    prev_action,\n",
    "                    observation_sequence[:, t:t+1] \n",
    "                )\n",
    "                reward_th = to_twohot(reward_sequence[:, t:t+1], self.reward_predictor.buckets_rew)\n",
    "\n",
    "                prior_latent_logits = self.dynamics_predictor(hidden_state)\n",
    "                dec_mu, dec_sig = self.decoder(hidden_state, posterior_latent)\n",
    "                rew_logits = self.reward_predictor(hidden_state, posterior_latent) \n",
    "                _, cont_logits = self.continue_predictor(hidden_state, posterior_latent)\n",
    "\n",
    "                observation_log_likelyhood = gaussian_log_probability(observation_sequence[:, t:t+1], dec_mu, dec_sig)\n",
    "                continue_log_likelyhood = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "                    cont_logits,\n",
    "                    continue_sequence[:, t:t+1],\n",
    "                    reduction='none'\n",
    "                )\n",
    "                reward_log_probs = torch.nn.functional.log_softmax(rew_logits, dim=-1)\n",
    "                reward_log_likelyhood = reward_th * reward_log_probs\n",
    "\n",
    "                posterior_logits.append(posterior_logits_t)\n",
    "                prior_logits.append(prior_latent_logits)\n",
    "                obs_likelyhood_seq.append(observation_log_likelyhood)\n",
    "                rew_likelyhood_seq.append(reward_log_likelyhood)\n",
    "                cont_likelyhood_seq.append(continue_log_likelyhood)\n",
    "            \n",
    "            prior_logits = torch.stack(prior_logits, dim=1)\n",
    "            posterior_logits = torch.stack(posterior_logits, dim=1)\n",
    "            obs_likelyhood_seq = torch.stack(obs_likelyhood_seq, dim=1)\n",
    "            rew_likelyhood_seq = torch.stack(rew_likelyhood_seq, dim=1)\n",
    "            cont_likelyhood_seq = torch.stack(cont_likelyhood_seq, dim=1)\n",
    "            \n",
    "            return (\n",
    "                prior_logits.squeeze(0), \n",
    "                posterior_logits.squeeze(0), \n",
    "                obs_likelyhood_seq.squeeze(0), \n",
    "                rew_likelyhood_seq.squeeze(0), \n",
    "                cont_likelyhood_seq.squeeze(0)\n",
    "            )\n",
    "\n",
    "        batched_sequence_unroll = torch.vmap(single_sequence_unroll, in_dims=(0,0,0,0), randomness='different')\n",
    "        prior_logits, posterior_logits, obs_log_lh, rew_log_lh, cont_log_lh = batched_sequence_unroll(\n",
    "            observation_sequence_batch,\n",
    "            action_sequence_batch,\n",
    "            reward_sequence_batch,\n",
    "            continue_sequence_batch\n",
    "        )\n",
    "        return (\n",
    "            prior_logits, \n",
    "            posterior_logits, \n",
    "            obs_log_lh, \n",
    "            rew_log_lh, \n",
    "            cont_log_lh\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75399142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll_model(\n",
    "        self,\n",
    "        observation_sequence_batch: torch.tensor, \n",
    "        action_sequence_batch: torch.tensor, \n",
    "        reward_sequence_batch: torch.tensor, \n",
    "        continue_sequence_batch: torch.tensor\n",
    "    ):\n",
    "    prior_logits = []\n",
    "    posterior_logits = []\n",
    "    obs_log_lh = []\n",
    "    rew_log_lh = []\n",
    "    cont_log_lh = []\n",
    "    B = continue_sequence_batch.shape[0]\n",
    "    hidden_state_batch = torch.zeros(B, 1, self.hidden_dims, dtype=torch.float32, device=self.device)\n",
    "    posterior_latent_batch = torch.zeros(B, 1, self.latent_num_rows, self.latent_num_columns, dtype=torch.float32, device=self.device)\n",
    "    for t in range(self.horizon):\n",
    "        prev_action_batch = action_sequence_batch[:, t-1:t] if t > 0 else torch.zeros(B, 1, self.action_dims, device=self.device)\n",
    "        posterior_latent_batch, hidden_state_batch, posterior_logits_batch = self.observe_step(\n",
    "            posterior_latent_batch,\n",
    "            hidden_state_batch,\n",
    "            prev_action_batch,                    \n",
    "            observation_sequence_batch[:, t:t+1] \n",
    "        )\n",
    "        reward_th_batch = to_twohot(reward_sequence_batch[:, t:t+1], self.reward_predictor.buckets_rew)\n",
    "\n",
    "        prior_latent_logits_batch = self.dynamics_predictor(hidden_state_batch)\n",
    "        dec_mu_batch, dec_sig_batch = self.decoder(hidden_state_batch, posterior_latent_batch)\n",
    "        reward_logits_batch = self.reward_predictor(hidden_state_batch, posterior_latent_batch) \n",
    "        _, cont_logits_batch = self.continue_predictor(hidden_state_batch, posterior_latent_batch)\n",
    "\n",
    "        observation_log_likelyhood_batch = gaussian_log_probability(observation_sequence_batch[:, t:t+1], dec_mu_batch, dec_sig_batch)\n",
    "        continue_log_likelyhood_batch = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "            cont_logits_batch,\n",
    "            continue_sequence_batch[:, t:t+1],\n",
    "            reduction='none'\n",
    "        )\n",
    "        reward_log_probs_batch = torch.nn.functional.log_softmax(reward_logits_batch, dim=-1)\n",
    "        reward_log_likelyhood_batch = torch.sum(reward_th_batch * reward_log_probs_batch, dim=-1, keepdim=True)\n",
    "\n",
    "        posterior_logits.append(posterior_logits_batch)\n",
    "        prior_logits.append(prior_latent_logits_batch)\n",
    "        obs_log_lh.append(observation_log_likelyhood_batch)\n",
    "        rew_log_lh.append(reward_log_likelyhood_batch)\n",
    "        cont_log_lh.append(continue_log_likelyhood_batch)\n",
    "\n",
    "    posterior_logits = torch.stack(posterior_logits, dim=1).squeeze(dim=2)\n",
    "    prior_logits = torch.stack(prior_logits, dim=1).squeeze(dim=2)\n",
    "    obs_log_lh = torch.stack(obs_log_lh, dim=1).squeeze(dim=2)\n",
    "    rew_log_lh = torch.stack(rew_log_lh, dim=1).squeeze(dim=2)\n",
    "    cont_log_lh = torch.stack(cont_log_lh, dim=1).squeeze(dim=2)\n",
    "    return (\n",
    "            prior_logits, \n",
    "            posterior_logits, \n",
    "            obs_log_lh, \n",
    "            rew_log_lh, \n",
    "            cont_log_lh\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_RL_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
